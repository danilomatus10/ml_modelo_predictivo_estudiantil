# src/preprocessing.py
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE
from config import PROCESSED_DATA_PATH
import os

def preprocess_data():
    try:
        print("ğŸ” Paso 1: Leyendo datos...")
        df = pd.read_csv(PROCESSED_DATA_PATH)

        # Validar que el archivo tenga datos
        if df.empty:
            raise ValueError("âš ï¸ El archivo 'cleaned_data.csv' estÃ¡ vacÃ­o.")

        print(f"ğŸ“Š Dimensiones iniciales: {df.shape}")

        # Limpiar y mapear 'Target'
        print("ğŸ§¹ Paso 2: Limpieza de Target...")
        # Convertir a string y limpiar espacios
        df['Target'] = df['Target'].astype(str).str.strip()
        
        # Mantener solo filas con valores vÃ¡lidos
        valid_labels = ['Dropout', 'Graduate']
        df = df[df['Target'].isin(valid_labels)]
        
        # Mapear a 0 y 1
        df['Target'] = df['Target'].map({'Dropout': 0, 'Graduate': 1})
        
        # Validar que y no tenga NaN
        if df['Target'].isnull().any():
            print("âŒ Advertencia: Hay valores NaN en 'Target' despuÃ©s del mapeo")
            print("ğŸ” Valores Ãºnicos en 'Target':", df['Target'].unique())
            raise ValueError("La columna 'Target' contiene valores no vÃ¡lidos")

        print(f"âœ… Valores Ãºnicos en Target despuÃ©s del mapeo: {df['Target'].unique()}")

        # Feature Engineering
        print("ğŸ› ï¸ Paso 3: Feature Engineering...")
        df['GPA_1st_sem'] = df['Curricular units 1st sem (grade)'] / 20
        df['Approval_rate_1st_sem'] = df['Curricular units 1st sem (approved)'] / df['Curricular units 1st sem (enrolled)']
        df['Approval_rate_1st_sem'] = df['Approval_rate_1st_sem'].replace([np.inf, -np.inf], np.nan).fillna(0)
        df['Economic_index'] = (df['Unemployment rate'] + df['Inflation rate']) / df['GDP']
        df['Economic_index'] = df['Economic_index'].replace([np.inf, -np.inf], np.nan).fillna(0)

        # Separar caracterÃ­sticas y objetivo
        print("ğŸ§® Paso 4: Separando X y y...")
        X = df.drop(['Target', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)'], axis=1)
        y = df['Target']

        # Identificar columnas categÃ³ricas y numÃ©ricas
        print("ğŸ” Paso 5: Identificando columnas categÃ³ricas y numÃ©ricas...")
        categorical_cols = [
            'Marital status', 'Application mode', 'Course', 'Nacionality',
            "Mother's qualification", "Father's qualification",
            "Mother's occupation", "Father's occupation"
        ]
        
        numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
        print(f"ğŸ”¢ Columnas numÃ©ricas: {numeric_cols}")
        print(f"ğŸ”¤ Columnas categÃ³ricas: {categorical_cols}")

        # Pipeline de preprocesamiento
        print("ğŸ› ï¸ Paso 6: Aplicando preprocesamiento...")
        preprocessor = ColumnTransformer([
            ('num', StandardScaler(), numeric_cols),
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
        ])

        X_processed = preprocessor.fit_transform(X)

        # âœ… Convertir a matriz densa antes de guardar
        X_processed = X_processed.toarray()

        # Aplicar SMOTE
        print("ğŸ” Paso 7: Aplicando SMOTE...")
        smote = SMOTE(random_state=42)
        X_resampled, y_resampled = smote.fit_resample(X_processed, y)

        # Crear directorio si no existe
        os.makedirs('data/processed', exist_ok=True)

        # Guardar datos procesados
        print("ğŸ’¾ Paso 8: Guardando datos procesados...")
        pd.DataFrame(X_resampled).to_csv('data/processed/X_processed.csv', index=False)
        pd.Series(y_resampled).to_csv('data/processed/y.csv', index=False)
        print("âœ… Archivos generados correctamente en 'data/processed/'")

    except Exception as e:
        print(f"âŒ Error durante el preprocesamiento: {str(e)}")
        raise

if __name__ == "__main__":
    preprocess_data()