# Modelo Predictivo de DeserciÃ³n Estudiantil ğŸ“

## ğŸ“ Archivos generados
| Archivo | PropÃ³sito | JustificaciÃ³n |
|--------|----------|---------------|
| `cleaned_data.csv` | Datos limpios y validados | Para evitar repetir limpieza cada vez que se cargan datos |
| `X_processed.csv` | CaracterÃ­sticas procesadas | Listas para entrenamiento (numÃ©ricas, escaladas, balanceadas) |
| `y.csv` | Variable objetivo | Etiquetas binarias (0, 1) para clasificaciÃ³n |
| `best_model.pkl` | Modelo entrenado | ReutilizaciÃ³n sin reentrenamiento |

# 1. Cargar y limpiar datos
python src/data_loader.py

# 2. Preprocesamiento (con conversiÃ³n a denso)
python src/preprocessing.py

# 3. Entrenamiento con Bayesian Search
python src/train_model.py

# 4. AnÃ¡lisis exploratorio
jupyter notebook notebooks/01_EDA.ipynb

# 5. AnÃ¡lisis de clÃºsteres
jupyter notebook notebooks/02_Clustering.ipynb

# 6. AnÃ¡lisis de resultados
jupyter notebook notebooks/03_Resultados.ipynb

# 7. Generar informe EDA
jupyter nbconvert --to html notebooks/01_EDA.ipynb --output reports/EDA_Report.html

# 8. Ejecutar pruebas unitarias
pytest tests/

## Â¿Por quÃ© generamos `X_processed.csv` y `y.csv`?
Estos archivos contienen:
- **`X_processed.csv`**: CaracterÃ­sticas procesadas (escaladas, codificadas y balanceadas)
- **`y.csv`**: Variable objetivo (`Target`) con etiquetas `0` (Dropout) y `1` (Graduate)

### Â¿Por quÃ© los separamos?
- **Reproducibilidad**: Permite reentrenar modelos sin repetir todo el preprocesamiento
- **Eficiencia**: Mejora el rendimiento al cargar solo las caracterÃ­sticas o el objetivo por separado
- **Claridad**: Facilita la interpretaciÃ³n y documentaciÃ³n del proceso

ğŸ§° InstalaciÃ³n
# 1. Clonar el repositorio
git clone https://github.com/danilomatus10/ml_modelo_predictivo_estudiantil.git
cd ml_modelo_predictivo_estudiantil

# 2. Crear y activar el entorno
conda env create -f environment.yml
conda activate ml_modelo_predictivo_estudiantil

# 3. Instalar dependencias adicionales (si es necesario)
pip install imbalanced-learn shap

ğŸ“ Estructura del Proyecto

ml_modelo_predictivo_estudiantil/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Datos originales (no versionados)
â”‚   â”‚   â””â”€â”€ data.csv         # Archivo CSV original
â”‚   â””â”€â”€ processed/             # Datos procesados
â”‚       â”œâ”€â”€ cleaned_data.csv   # Datos limpios
â”‚       â”œâ”€â”€ X_processed.csv    # Datos procesados
â”‚       â””â”€â”€ y.csv            # Etiquetas
â”‚
â”œâ”€â”€ notebooks/                 # Notebooks Jupyter
â”‚   â”œâ”€â”€ 01_EDA.ipynb         # AnÃ¡lisis Exploratorio
â”‚   â”œâ”€â”€ 02_Clustering.ipynb   # AnÃ¡lisis de clÃºsteres
â”‚   â””â”€â”€ 03_Resultados.ipynb  # Resultados del modelo
â”‚
â”œâ”€â”€ src/                       # CÃ³digo fuente
â”‚   â”œâ”€â”€ config.py              # ConfiguraciÃ³n de rutas
â”‚   â”œâ”€â”€ data_loader.py         # Carga de datos
â”‚   â”œâ”€â”€ preprocessing.py       # Pipelines de preprocesamiento
â”‚   â””â”€â”€ train_model.py         # Entrenamiento de modelos
â”‚
â”œâ”€â”€ models/                    # Modelos entrenados
â”‚   â””â”€â”€ best_model.pkl        # Modelo serializado
â”‚
â”œâ”€â”€ reports/                   # Informes y visualizaciones
â”‚   â”œâ”€â”€ EDA_Report.html
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ clusters_visualization.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ shap_importance.png
â”‚
â”œâ”€â”€ tests/                     # Pruebas unitarias
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_data_loading.py
â”‚
â”œâ”€â”€ environment.yml            # Entorno actualizado
â””â”€â”€ README.md                  # DocumentaciÃ³n del proyecto

â–¶ï¸ EjecuciÃ³n del Proyecto

# 1. Cargar y limpiar datos
python src/data_loader.py

# 2. Preprocesamiento (con validaciÃ³n de datos numÃ©ricos)
python src/preprocessing.py

# 3. Entrenamiento con Bayesian Search
python src/train_model.py

# 4. Generar informe EDA
jupyter nbconvert --to html notebooks/01_EDA.ipynb --output reports/EDA_Report.html

# 5. AnÃ¡lisis de clÃºsteres
jupyter notebook notebooks/02_Clustering.ipynb

# 6. AnÃ¡lisis de resultados
jupyter notebook notebooks/03_Resultados.ipynb

# 7. Ejecutar pruebas unitarias
pytest tests/


ğŸ“‹ Autores 

    Hubert GutiÃ©rrez   
    Danilo Matus   
    Enllely Roque 


ğŸ› ï¸ ResoluciÃ³n de Problemas Comunes 
âŒ Error: "could not convert string to float" 

Causa : Archivos CSV procesados con matrices dispersas (formato incorrecto).
SoluciÃ³n :   

    1. AsegÃºrate de que preprocessing.py incluya:
    X_resampled = X_resampled.toarray()  # Convierte a matriz densa

    Elimina archivos antiguos antes de regenerar:
     

rm data/processed/X_processed.csv
rm data/processed/y.csv
python src/preprocessing.py

 
âŒ Error: "No module named 'notebook.services'" 

Causa : Falta la librerÃ­a notebook para nbconvert.
SoluciÃ³n :   

1 pip install notebook
 
 
ğŸ“ Notas Importantes 

    Datos confidenciales : Si data.csv contiene informaciÃ³n sensible, no lo subas a GitHub . EnvÃ­alo al docente por correo.
    Reproducibilidad : Todos los pasos deben ejecutarse en orden para garantizar consistencia.
    InterpretaciÃ³n del modelo : Usa SHAP para explicar predicciones individuales.
     

